{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JSJeong-me/EasyGPT-2023/blob/main/Instructing_LLMs_To_Match_Tone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72d39d60",
      "metadata": {
        "id": "72d39d60"
      },
      "source": [
        "# Instructing LLMs To Match Tone\n",
        "\n",
        "LLMs that generate text are awesome, but what if you want to edit the tone/style it responds with?\n",
        "\n",
        "We've all seen the [pirate](https://python.langchain.com/en/latest/modules/agents/agents/custom_llm_agent.html#:~:text=template%20%3D%20%22%22%22Answer%20the%20following%20questions%20as%20best%20you%20can%2C%20but%20speaking%20as%20a%20pirate%20might%20speak.%20You%20have%20access%20to%20the%20following%20tools%3A) examples, but it would be awesome if we could tune the prompt to match the tone of specific people?\n",
        "\n",
        "Below is a series of techniques aimed to generate text in the tone and style you want. No single technique will likely be *exactly* what you need, but I guarantee you can iterate with these tips to get a solid outcome for your project.\n",
        "\n",
        "But Greg, what about fine tuning? Fine tuning would likely give you a fabulous result, but the barriers to entry are too high for the average developer (as of May '23). I would rather get the 87% solution today rather than not ship something. If you're doing this in production and your differentiator is your ability to adapt to different styles you'll likely want to explore fine tuning.\n",
        "\n",
        "If you want to see a demo video of this, check out the Twitter post. For a full explination head over to YouTube.\n",
        "\n",
        "### 4 Levels Of Tone Matching Techniques:\n",
        "1. **Simple:** As a human, try and describe the tone you would like\n",
        "2. **Intermediate:** Include your description + examples\n",
        "3. **AI-Assisted:** Ask the LLM to extract tone, use their output in your next prompt\n",
        "4. **Technique Fusion:** Combine multiple techniques to mimic tone\n",
        "\n",
        "**Today's Goal**: Generate tweets mimicking the style of online personalities. You could customize this code to generate emails, chat messages, writing, etc.\n",
        "\n",
        "First let's import our packages"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install python-dotenv"
      ],
      "metadata": {
        "id": "b7dF6JTihsK0"
      },
      "id": "b7dF6JTihsK0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SiEzUvdrhz80"
      },
      "id": "SiEzUvdrhz80",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e65bd69a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e65bd69a",
        "outputId": "1647252d-3465-45f9-f044-1e5fccd42f5d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# LangChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "# Environment Variables\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Twitter\n",
        "import tweepy\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83886158",
      "metadata": {
        "id": "83886158"
      },
      "source": [
        "Set your OpenAI key. You can either put it as an environment variable or in the string below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "98123655",
      "metadata": {
        "hide_input": false,
        "id": "98123655"
      },
      "outputs": [],
      "source": [
        "openai_api_key = os.getenv('OPENAI_API_KEY', 'sk-')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60e572c7",
      "metadata": {
        "id": "60e572c7"
      },
      "source": [
        "We'll be using `gpt-4` today, but you can swap out for `gpt-3.5-turbo` if you'd like"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "063daa43",
      "metadata": {
        "id": "063daa43"
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(temperature=0, openai_api_key=openai_api_key, model_name='gpt-4')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c76a9b7c",
      "metadata": {
        "id": "c76a9b7c"
      },
      "source": [
        "## Method #1: Simple - Describe the tone you would like\n",
        "\n",
        "Our first method is going to be simply describing the tone we would like.\n",
        "\n",
        "Let's try a few exmaples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0c852071",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c852071",
        "outputId": "f01d1ee8-8309-482f-a6ba-a3692bca1ba1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"고객님의 만족이 저희에게 큰 힘이 됩니다! 앞으로도 좋은 상품으로 보답하겠습니다. 감사합니다 😊🙏👍\"\n"
          ]
        }
      ],
      "source": [
        "prompt = \"\"\"\n",
        "'별 기대 없이 샀는데 상당히 옷이 괜찮고 예쁘네요 깔별로 쟁일 생각 무탠다드 가성비 오지네요' 에 대한 댓글을 만들어 주세요.\n",
        "\n",
        "% RESPONSE CONTENT:\n",
        "    - Write a comment with gratitude for using the shopping mall and a desire for continued business.\n",
        "\n",
        "% RESPONSE FORMAT:\n",
        "\n",
        "    - Respond in under 500 characters\n",
        "    - Respond in three or less short sentences\n",
        "    - emojis\n",
        "\"\"\"\n",
        "\n",
        "output = llm.predict(prompt)\n",
        "print (output)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}