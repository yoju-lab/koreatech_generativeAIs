{"cells":[{"cell_type":"markdown","id":"ae55c84f","metadata":{"id":"ae55c84f"},"source":["# Autoregressive (자동회귀) 문장 생성\n","\n","간단한 자동 회귀적인 텍스트 생성을 위한 코드 예제입니다. 여기서는 OpenAI의 GPT-2 모델을 사용하는데, GPT-3은 API를 통해서만 직접 사용할 수 있기 때문입니다. 그럼에도 GPT-2는 GPT-3와 매우 유사한 구조를 가지고 있으므로, 동일한 접근 방식을 사용합니다.\n","\n","### Colab에서 실행"]},{"cell_type":"code","execution_count":2,"id":"4f48a4f2","metadata":{"id":"4f48a4f2","executionInfo":{"status":"ok","timestamp":1705727582969,"user_tz":-540,"elapsed":5310,"user":{"displayName":"오상훈","userId":"14443967796468878887"}}},"outputs":[],"source":["!pip install -q transformers # create huggingface.co"]},{"cell_type":"code","execution_count":3,"id":"00b75689","metadata":{"id":"00b75689","executionInfo":{"status":"ok","timestamp":1705727588441,"user_tz":-540,"elapsed":1216,"user":{"displayName":"오상훈","userId":"14443967796468878887"}}},"outputs":[],"source":["import torch\n","from transformers import GPT2LMHeadModel, GPT2Tokenizer\n","\n","# 토크나이저 초기화\n","tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-medium\")"]},{"cell_type":"code","source":["# 문장 시작 부분\n","input_text = \"Once upon a time\"\n","input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n","input_ids"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2VuivpMRSc-_","executionInfo":{"status":"ok","timestamp":1705727614643,"user_tz":-540,"elapsed":477,"user":{"displayName":"오상훈","userId":"14443967796468878887"}},"outputId":"7daa25e5-388e-4c05-9749-12009019a1b2"},"id":"2VuivpMRSc-_","execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[7454, 2402,  257,  640]])"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["# 모델 초기화\n","model = GPT2LMHeadModel.from_pretrained(\"gpt2-medium\")"],"metadata":{"id":"FBQkeGFzSYXJ","executionInfo":{"status":"ok","timestamp":1705727657821,"user_tz":-540,"elapsed":9144,"user":{"displayName":"오상훈","userId":"14443967796468878887"}}},"id":"FBQkeGFzSYXJ","execution_count":5,"outputs":[]},{"cell_type":"code","execution_count":10,"id":"92f576b2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"92f576b2","executionInfo":{"status":"ok","timestamp":1705727878963,"user_tz":-540,"elapsed":9943,"user":{"displayName":"오상훈","userId":"14443967796468878887"}},"outputId":"3fc83137-246e-4197-d613-dbaf948f3a87"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 7454,  2402,   257,   640,    11,   612,   373,   257,   582,   508,\n","          5615,   287,   257,  7404,  1444,   509, 17716,   322,    13,   679,\n","           373,   257,   845,   922,   582,    11,   290,   339,   373,   845,\n","          1611,   284,   465,  1751,    13,  1881,  1110,    11,   339,   373,\n","          6155,  1863,   262,  2975,    11,   290,   339,  2497,   257,  2415]])"]},"metadata":{},"execution_count":10}],"source":["# 문장 생성 (auto-regressive 사용)\n","output = model.generate(input_ids, max_length=50, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)\n","output"]},{"cell_type":"code","source":["# try to apply temperature param\n","output = model.generate(input_ids, max_length=50, num_return_sequences=1, temperature=1, pad_token_id=tokenizer.eos_token_id)\n","output"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rVjyiiaaVTHs","executionInfo":{"status":"ok","timestamp":1705728445430,"user_tz":-540,"elapsed":9970,"user":{"displayName":"오상훈","userId":"14443967796468878887"}},"outputId":"b9ee2aca-aae0-414d-a47d-eb84b748c20d"},"id":"rVjyiiaaVTHs","execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 7454,  2402,   257,   640,    11,   612,   373,   257,   582,   508,\n","          5615,   287,   257,  7404,  1444,   509, 17716,   322,    13,   679,\n","           373,   257,   845,   922,   582,    11,   290,   339,   373,   845,\n","          1611,   284,   465,  1751,    13,  1881,  1110,    11,   339,   373,\n","          6155,  1863,   262,  2975,    11,   290,   339,  2497,   257,  2415]])"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["# try change max_length value\n","output = model.generate(input_ids, max_length=20, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)\n","output"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WO3A9cD9TkXX","executionInfo":{"status":"ok","timestamp":1705727986082,"user_tz":-540,"elapsed":3245,"user":{"displayName":"오상훈","userId":"14443967796468878887"}},"outputId":"9281bbbc-6d7c-4b37-defa-4300cbf4f7af"},"id":"WO3A9cD9TkXX","execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 7454,  2402,   257,   640,    11,   612,   373,   257,   582,   508,\n","          5615,   287,   257,  7404,  1444,   509, 17716,   322,    13,   679]])"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","execution_count":13,"id":"967494d6","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"967494d6","executionInfo":{"status":"ok","timestamp":1705728012545,"user_tz":-540,"elapsed":488,"user":{"displayName":"오상훈","userId":"14443967796468878887"}},"outputId":"37e6e5b8-296d-4128-f6bc-c748cfa2a490"},"outputs":[{"output_type":"stream","name":"stdout","text":["Generated text 1: Once upon a time, there was a man who lived in a village called Krakow. He\n"]}],"source":["# 생성된 문장 출력\n","for i, generated_text in enumerate(output):\n","    decoded_text = tokenizer.decode(generated_text, skip_special_tokens=True)\n","    print(f\"Generated text {i + 1}: {decoded_text}\")"]},{"cell_type":"markdown","id":"c10e2ff5","metadata":{"id":"c10e2ff5"},"source":["GPT-2는 자체적으로 autoregressive 모델입니다. \"Autoregressive\"란, 이전에 생성된 토큰들을 기반으로 다음 토큰을 생성하는 모델을 의미합니다.\n","\n","위의 코드에서 `model.generate` 메서드는 이미 autoregressive한 방식으로 문장을 생성합니다. 그러나 이를 명시적으로 보여주기 위해 각 단계에서 토큰을 하나씩 생성하는 autoregressive한 코드를 아래에 작성하겠습니다:"]},{"cell_type":"code","execution_count":5,"id":"9c8ab4dc","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9c8ab4dc","executionInfo":{"status":"ok","timestamp":1705726100634,"user_tz":-540,"elapsed":6,"user":{"displayName":"오상훈","userId":"14443967796468878887"}},"outputId":"24d9c941-23e5-4917-8332-e0194eebf629"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[7454, 2402,  257,  640]])"]},"metadata":{},"execution_count":5}],"source":["# 문장 시작 부분\n","input_text = \"Once upon a time\"\n","input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n","input_ids"]},{"cell_type":"markdown","id":"cb5ba82e","metadata":{"id":"cb5ba82e"},"source":["input_ids를 입력으로 받아 next token의 확률 분포를 예측값으로 반환 받습니다."]},{"cell_type":"code","execution_count":6,"id":"84a6c12f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"84a6c12f","executionInfo":{"status":"ok","timestamp":1705726101240,"user_tz":-540,"elapsed":610,"user":{"displayName":"오상훈","userId":"14443967796468878887"}},"outputId":"fa6f3361-284a-439e-f561-5fb20d486b9e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[ -74.6887,  -74.2220,  -80.2354,  ...,  -83.7431,  -80.4567,\n","           -76.2926],\n","         [-225.0849, -225.3535, -229.2500,  ..., -236.9878, -237.3179,\n","          -224.3200],\n","         [  -6.1224,   -4.9656,  -10.4817,  ...,  -13.5870,  -12.2557,\n","            -5.6444],\n","         [  -9.2671,   -7.4639,  -14.5420,  ...,  -16.8138,  -16.4736,\n","            -9.4272]]], grad_fn=<UnsafeViewBackward0>)"]},"metadata":{},"execution_count":6}],"source":["predictions = model(input_ids)\n","logits = predictions.logits\n","logits"]},{"cell_type":"markdown","id":"e8d59498","metadata":{"id":"e8d59498"},"source":["예측값 중 가장 큰 값의 token을 선택합니다."]},{"cell_type":"code","execution_count":7,"id":"83bc0992","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"83bc0992","executionInfo":{"status":"ok","timestamp":1705726106851,"user_tz":-540,"elapsed":5613,"user":{"displayName":"오상훈","userId":"14443967796468878887"}},"outputId":"d5e6bd02-d830-4b77-c2e9-d13f66aa8c64"},"outputs":[{"output_type":"stream","name":"stdout","text":["예측한 next token : 11\n","decoding한 next token : ,\n"]}],"source":["predicted_token = torch.argmax(logits[0, -1]).item()\n","\n","print(f\"예측한 next token : {predicted_token}\")\n","token = tokenizer.decode(predicted_token, skip_special_tokens=True)\n","print(f\"decoding한 next token : {token}\")"]},{"cell_type":"markdown","id":"d50ff737","metadata":{"id":"d50ff737"},"source":["위와 같은 방식으로 마지막 단어 이어 붙이기 형식의 문장 생성을 합니다."]},{"cell_type":"code","source":["# Autoregressive한 방식으로 문장 생성\n","max_length = 20                     # 생성할 문장의 최대 길이 설정\n","input_ids_concat = input_ids  # 초기 입력 토큰(예: 문장의 시작 부분)\n","\n","# 생성할 문장의 길이가 max_length보다 작을 동안 반복\n","while input_ids_concat.shape[1] < max_length:\n","    # 모델을 사용하여 다음 토큰 예측\n","    predictions = model(input_ids_concat)\n","    logits = predictions.logits                  # 예측된 로짓을 가져옴\n","    predicted_token = torch.argmax(logits[0, -1]).item()  # 로짓에서 가장 확률이 높은 토큰을 선택\n","\n","    # 예측된 토큰을 기존의 입력 토큰 뒤에 추가\n","    input_ids_concat = torch.cat([input_ids_concat, torch.tensor([[predicted_token]])], dim=1)\n","    print(input_ids_concat)   # 현재까지 예측된 토큰들을 출력\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7laVATwKUQHH","executionInfo":{"status":"ok","timestamp":1705728093875,"user_tz":-540,"elapsed":7474,"user":{"displayName":"오상훈","userId":"14443967796468878887"}},"outputId":"5c8833de-392a-4ce5-ca4b-9d1835cbb3ed"},"id":"7laVATwKUQHH","execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[7454, 2402,  257,  640,   11]])\n","tensor([[7454, 2402,  257,  640,   11,  612]])\n","tensor([[7454, 2402,  257,  640,   11,  612,  373]])\n","tensor([[7454, 2402,  257,  640,   11,  612,  373,  257]])\n","tensor([[7454, 2402,  257,  640,   11,  612,  373,  257,  582]])\n","tensor([[7454, 2402,  257,  640,   11,  612,  373,  257,  582,  508]])\n","tensor([[7454, 2402,  257,  640,   11,  612,  373,  257,  582,  508, 5615]])\n","tensor([[7454, 2402,  257,  640,   11,  612,  373,  257,  582,  508, 5615,  287]])\n","tensor([[7454, 2402,  257,  640,   11,  612,  373,  257,  582,  508, 5615,  287,\n","          257]])\n","tensor([[7454, 2402,  257,  640,   11,  612,  373,  257,  582,  508, 5615,  287,\n","          257, 7404]])\n","tensor([[7454, 2402,  257,  640,   11,  612,  373,  257,  582,  508, 5615,  287,\n","          257, 7404, 1444]])\n","tensor([[7454, 2402,  257,  640,   11,  612,  373,  257,  582,  508, 5615,  287,\n","          257, 7404, 1444,  509]])\n","tensor([[ 7454,  2402,   257,   640,    11,   612,   373,   257,   582,   508,\n","          5615,   287,   257,  7404,  1444,   509, 17716]])\n","tensor([[ 7454,  2402,   257,   640,    11,   612,   373,   257,   582,   508,\n","          5615,   287,   257,  7404,  1444,   509, 17716,   322]])\n","tensor([[ 7454,  2402,   257,   640,    11,   612,   373,   257,   582,   508,\n","          5615,   287,   257,  7404,  1444,   509, 17716,   322,    13]])\n","tensor([[ 7454,  2402,   257,   640,    11,   612,   373,   257,   582,   508,\n","          5615,   287,   257,  7404,  1444,   509, 17716,   322,    13,   679]])\n"]}]},{"cell_type":"code","execution_count":15,"id":"74339413","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"74339413","executionInfo":{"status":"ok","timestamp":1705728146030,"user_tz":-540,"elapsed":5,"user":{"displayName":"오상훈","userId":"14443967796468878887"}},"outputId":"37fdc58a-3d4d-493f-925b-fc320545737e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Once upon a time, there was a man who lived in a village called Krakow. He\n"]}],"source":["# 최종적으로 생성된 문장 출력\n","decoded_text = tokenizer.decode(input_ids_concat[0], skip_special_tokens=True)\n","print(decoded_text)  # 디코딩하여 텍스트 형태로 출력"]},{"cell_type":"code","execution_count":8,"id":"573d7029","metadata":{"id":"573d7029","executionInfo":{"status":"ok","timestamp":1705726116735,"user_tz":-540,"elapsed":24,"user":{"displayName":"오상훈","userId":"14443967796468878887"}}},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}