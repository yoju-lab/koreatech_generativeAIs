{"cells":[{"cell_type":"markdown","source":["##  문장 내의 단어들을 임베딩\n","아래 조건으로 영문 문장 4개 리스트를 Embedding 작성\n","- keras.layers.Embedding 사용\n","- 영문 문장은 100자 적용"],"metadata":{"id":"IcQJ-w6txvkY"},"id":"IcQJ-w6txvkY"},{"cell_type":"code","source":["import keras\n","\n","# 영문 문장 4개 리스트 생성\n","sentences = [\n","    \"The quick brown fox jumps over the lazy dog.\",\n","    \"I love you.\",\n","    \"The world is a beautiful place.\",\n","    \"I am a data scientist.\"\n","]\n","\n","# 단어 사전 생성\n","word_index = keras.datasets.imdb.get_word_index()\n","word_index = {k: v + 3 for k, v in word_index.items()}\n","word_index[\"<PAD>\"] = 0\n","word_index[\"<UNK>\"] = 1\n","\n","# 단어 토큰화\n","tokens = []\n","for sentence in sentences:\n","    tokens.append(keras.preprocessing.text.text_to_word_sequence(sentence))\n","\n","# Embedding 레이어 생성\n","embedding_layer = keras.layers.Embedding(\n","    input_dim=len(word_index),\n","    output_dim=100,\n","    mask_zero=True,\n","    trainable=False\n",")\n","\n","# Embedding 적용\n","embedded_sentences = embedding_layer(tokens)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":506},"id":"BgKpeoO9xqmW","executionInfo":{"status":"error","timestamp":1705719038064,"user_tz":-540,"elapsed":11951,"user":{"displayName":"오상훈","userId":"14443967796468878887"}},"outputId":"d83eaa63-d407-4590-a38e-bc3493e471ce"},"id":"BgKpeoO9xqmW","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n","1641221/1641221 [==============================] - 0s 0us/step\n"]},{"output_type":"error","ename":"AttributeError","evalue":"Exception encountered when calling layer 'embedding' (type Embedding).\n\n'list' object has no attribute 'dtype'\n\nCall arguments received by layer 'embedding' (type Embedding):\n  • inputs=[[\"'the'\", \"'quick'\", \"'brown'\", \"'fox'\", \"'jumps'\", \"'over'\", \"'the'\", \"'lazy'\", \"'dog'\"], [\"'i'\", \"'love'\", \"'you'\"], [\"'the'\", \"'world'\", \"'is'\", \"'a'\", \"'beautiful'\", \"'place'\"], [\"'i'\", \"'am'\", \"'a'\", \"'data'\", \"'scientist'\"]]","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-d84df0dba8ed>\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Embedding 적용\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0membedded_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\u001b[0m in \u001b[0;36mdtype\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1596\u001b[0m     \"\"\"\n\u001b[0;32m-> 1597\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: Exception encountered when calling layer 'embedding' (type Embedding).\n\n'list' object has no attribute 'dtype'\n\nCall arguments received by layer 'embedding' (type Embedding):\n  • inputs=[[\"'the'\", \"'quick'\", \"'brown'\", \"'fox'\", \"'jumps'\", \"'over'\", \"'the'\", \"'lazy'\", \"'dog'\"], [\"'i'\", \"'love'\", \"'you'\"], [\"'the'\", \"'world'\", \"'is'\", \"'a'\", \"'beautiful'\", \"'place'\"], [\"'i'\", \"'am'\", \"'a'\", \"'data'\", \"'scientist'\"]]"]}]},{"cell_type":"code","source":[],"metadata":{"id":"KxnyhIoNxrGf"},"id":"KxnyhIoNxrGf","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}