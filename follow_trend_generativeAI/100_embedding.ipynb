{"cells":[{"cell_type":"markdown","id":"c387e7ef","metadata":{"id":"c387e7ef"},"source":["#  문장 내의 단어들을 임베딩\n","- keras.layers.Embedding 레이어 사용"]},{"cell_type":"code","execution_count":7,"id":"0db507fb","metadata":{"id":"0db507fb","executionInfo":{"status":"ok","timestamp":1705717956340,"user_tz":-540,"elapsed":283,"user":{"displayName":"오상훈","userId":"14443967796468878887"}}},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.layers import Embedding\n","\n","# 샘플 데이터: 간단한 문장들의 모음\n","sentences = [\n","    \"I love machine learning\",\n","    \"I love coding in Python\",\n","    \"Deep learning is fun\"\n","]"]},{"cell_type":"code","execution_count":8,"id":"3dc90226","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3dc90226","executionInfo":{"status":"ok","timestamp":1705717956642,"user_tz":-540,"elapsed":11,"user":{"displayName":"오상훈","userId":"14443967796468878887"}},"outputId":"741834e8-feaa-46cc-a5d8-bc16928adce4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'I': 1,\n"," 'love': 2,\n"," 'machine': 3,\n"," 'learning': 4,\n"," 'coding': 5,\n"," 'in': 6,\n"," 'Python': 7,\n"," 'Deep': 8,\n"," 'is': 9,\n"," 'fun': 10}"]},"metadata":{},"execution_count":8}],"source":["# 각 문장을 단어로 분할하고, 각 단어에 대한 고유한 인덱스를 생성\n","word_index = {}\n","\n","for sentence in sentences:\n","    for word in sentence.split():\n","        if word not in word_index:\n","            word_index[word] = len(word_index) + 1\n","\n","word_index"]},{"cell_type":"code","execution_count":9,"id":"98af754a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"98af754a","executionInfo":{"status":"ok","timestamp":1705717956643,"user_tz":-540,"elapsed":10,"user":{"displayName":"오상훈","userId":"14443967796468878887"}},"outputId":"e5b68253-01c0-482e-fe71-01612d649261"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[1, 2, 3, 4], [1, 2, 5, 6, 7], [8, 4, 9, 10]]"]},"metadata":{},"execution_count":9}],"source":["# 문장들을 단어 인덱스의 시퀀스로 변환\n","sequences = [[word_index[word] for word in sentence.split()] for sentence in sentences]\n","sequences"]},{"cell_type":"code","execution_count":10,"id":"51c37c9c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"51c37c9c","executionInfo":{"status":"ok","timestamp":1705717956643,"user_tz":-540,"elapsed":8,"user":{"displayName":"오상훈","userId":"14443967796468878887"}},"outputId":"fedf8717-ebd2-4edd-e055-efe4a97f86e4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 1,  2,  3,  4,  0],\n","       [ 1,  2,  5,  6,  7],\n","       [ 8,  4,  9, 10,  0]], dtype=int32)"]},"metadata":{},"execution_count":10}],"source":["# 문장들 중 가장 긴 것의 길이를 구함\n","max_length = max([len(seq) for seq in sequences])\n","\n","# 모든 문장을 가장 긴 문장의 길이로 패딩\n","padded_sequences = tf.keras.preprocessing.sequence.pad_sequences(sequences, maxlen=max_length, padding='post')\n","padded_sequences"]},{"cell_type":"code","execution_count":11,"id":"bddcd17f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bddcd17f","executionInfo":{"status":"ok","timestamp":1705717956643,"user_tz":-540,"elapsed":7,"user":{"displayName":"오상훈","userId":"14443967796468878887"}},"outputId":"2ea54f81-6867-476f-b181-783900344658"},"outputs":[{"output_type":"stream","name":"stdout","text":["(3, 5, 8)\n","tf.Tensor(\n","[[[ 0.02292763  0.01898408  0.03058434  0.03767885 -0.00078635\n","   -0.04131095  0.01049863 -0.01070913]\n","  [-0.03095946 -0.01208802 -0.01741817  0.01822146  0.01489382\n","   -0.04860253 -0.02816772  0.04655448]\n","  [-0.03956745 -0.02778288 -0.01271453 -0.0489408   0.01927609\n","   -0.03345201 -0.01254299 -0.03338441]\n","  [-0.00717854  0.01874379  0.04830558  0.03144133 -0.02392714\n","    0.02617493  0.03784785  0.03108868]\n","  [ 0.0118425   0.0198478  -0.04260274  0.04898245  0.03648787\n","    0.04960028 -0.0072081  -0.00678673]]\n","\n"," [[ 0.02292763  0.01898408  0.03058434  0.03767885 -0.00078635\n","   -0.04131095  0.01049863 -0.01070913]\n","  [-0.03095946 -0.01208802 -0.01741817  0.01822146  0.01489382\n","   -0.04860253 -0.02816772  0.04655448]\n","  [ 0.01120577 -0.00184532  0.01643792  0.00330768  0.02645927\n","    0.02163352 -0.03643812  0.04222197]\n","  [-0.01672084  0.01964724 -0.02386712 -0.03663919  0.04117819\n","   -0.01197306 -0.02973223 -0.04192952]\n","  [-0.00805389 -0.00713674  0.01546675  0.01619751 -0.0189808\n","   -0.00284543  0.04655034  0.04955767]]\n","\n"," [[-0.01536431 -0.00179927 -0.0039075   0.04382097  0.04367017\n","   -0.02264318  0.02916554 -0.03942636]\n","  [-0.00717854  0.01874379  0.04830558  0.03144133 -0.02392714\n","    0.02617493  0.03784785  0.03108868]\n","  [ 0.04830645 -0.02558706  0.0393461  -0.01386217  0.01291418\n","    0.023085   -0.04153421 -0.010414  ]\n","  [ 0.03339373  0.04265321  0.04710582  0.02515472 -0.00867822\n","   -0.01984853  0.02428439  0.02233734]\n","  [ 0.0118425   0.0198478  -0.04260274  0.04898245  0.03648787\n","    0.04960028 -0.0072081  -0.00678673]]], shape=(3, 5, 8), dtype=float32)\n"]}],"source":["# Embedding 레이어 생성\n","embedding_dim = 8\n","embedding_layer = Embedding(input_dim=len(word_index) + 1, output_dim=embedding_dim, input_length=max_length)\n","\n","# 패딩된 시퀀스를 Embedding 레이어에 통과시켜 임베딩된 결과를 얻음\n","embedded_sequences = embedding_layer(padded_sequences)\n","\n","print(embedded_sequences.shape)\n","print(embedded_sequences)"]},{"cell_type":"code","execution_count":12,"id":"691a1486","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"691a1486","executionInfo":{"status":"ok","timestamp":1705717956643,"user_tz":-540,"elapsed":6,"user":{"displayName":"오상훈","userId":"14443967796468878887"}},"outputId":"c90e8038-e186-41d9-81c0-e718e64198bb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Embedding Layer Shape : (11, 8)\n","Embedding Layer Weights (Word Embeddings):\n"," [[ 0.0118425   0.0198478  -0.04260274  0.04898245  0.03648787  0.04960028\n","  -0.0072081  -0.00678673]\n"," [ 0.02292763  0.01898408  0.03058434  0.03767885 -0.00078635 -0.04131095\n","   0.01049863 -0.01070913]\n"," [-0.03095946 -0.01208802 -0.01741817  0.01822146  0.01489382 -0.04860253\n","  -0.02816772  0.04655448]\n"," [-0.03956745 -0.02778288 -0.01271453 -0.0489408   0.01927609 -0.03345201\n","  -0.01254299 -0.03338441]\n"," [-0.00717854  0.01874379  0.04830558  0.03144133 -0.02392714  0.02617493\n","   0.03784785  0.03108868]\n"," [ 0.01120577 -0.00184532  0.01643792  0.00330768  0.02645927  0.02163352\n","  -0.03643812  0.04222197]\n"," [-0.01672084  0.01964724 -0.02386712 -0.03663919  0.04117819 -0.01197306\n","  -0.02973223 -0.04192952]\n"," [-0.00805389 -0.00713674  0.01546675  0.01619751 -0.0189808  -0.00284543\n","   0.04655034  0.04955767]\n"," [-0.01536431 -0.00179927 -0.0039075   0.04382097  0.04367017 -0.02264318\n","   0.02916554 -0.03942636]\n"," [ 0.04830645 -0.02558706  0.0393461  -0.01386217  0.01291418  0.023085\n","  -0.04153421 -0.010414  ]\n"," [ 0.03339373  0.04265321  0.04710582  0.02515472 -0.00867822 -0.01984853\n","   0.02428439  0.02233734]]\n","\n","\n","Embedding for 'love':\n"," [-0.03095946 -0.01208802 -0.01741817  0.01822146  0.01489382 -0.04860253\n"," -0.02816772  0.04655448]\n"]}],"source":["# Embedding 레이어의 가중치 (단어 임베딩 행렬) 출력\n","embeddings = embedding_layer.get_weights()[0]\n","print(\"Embedding Layer Shape :\", embeddings.shape)\n","print(\"Embedding Layer Weights (Word Embeddings):\\n\", embeddings)\n","print()\n","\n","# 예: 'love'라는 단어의 임베딩 벡터를 출력\n","print(\"\\nEmbedding for 'love':\\n\", embeddings[word_index['love']])"]},{"cell_type":"markdown","id":"8bf45463","metadata":{"id":"8bf45463"},"source":["0은 보통 패딩을 나타내는 인덱스로 사용됩니다. 결과적으로, Embedding 레이어의 가중치 행렬의 크기는 (고유한 단어 수 + 1, 임베딩 벡터의 차원수)가 되므로, (11, 8)이 됩니다."]},{"cell_type":"code","execution_count":12,"id":"e0718544","metadata":{"id":"e0718544","executionInfo":{"status":"ok","timestamp":1705717956643,"user_tz":-540,"elapsed":4,"user":{"displayName":"오상훈","userId":"14443967796468878887"}}},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}